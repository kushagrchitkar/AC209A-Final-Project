{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4e4e6a-f941-424b-b7b4-c6e24e2dda0e",
   "metadata": {},
   "source": [
    "## Milestone 4:\n",
    "Milestone 4 continues to add more content to what will become the group's final notebook.  In addition to your refined problem statement and EDA, the new milestone notebook should now include the group's baseline model, pipeline, and interpretation of these initial results.\n",
    "\n",
    "To complete Milestone 4, students must submit a well organized and markdown-annotated Jupyter notebook with all relevant output visible.\n",
    "Helper utility .py files used by the notebook are also acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08babb2e-24ed-4d78-b42d-5bb36083fd2c",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "The Coffee Quality Institute provides coffee evaluations using tasting experts who score the coffees based on features such as acidity, body, and balance... and one subjective 'overall' scoring, but what contributes to this subjective component?  We set out to determine what features cause a coffee to receive a higher rating, and whether other variables like coffee origin contribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a5e60-ba48-4cfb-966d-5d86f11c3af5",
   "metadata": {},
   "source": [
    "**Question : Which features mostly impact our appreciation of the taste of coffee (the general grade given to a coffee) ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f11f110-4e35-4902-ac2d-7350375864ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82fe1bf-d3ac-4663-9b3e-d44af53e2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7dd1b9-145b-454a-825a-005f7818746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (1338, 43)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/merged_data_cleaned.csv')\n",
    "df = df.iloc[:,1:]\n",
    "\n",
    "# drop test datapoint\n",
    "df = df.drop(df[df['Harvest.Year'] == 'TEST'].index)\n",
    "\n",
    "print(\"Dataset shape: \",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d281bc-0aa0-4e9a-b45e-67db46aa7ff0",
   "metadata": {},
   "source": [
    "## Explore and Visualize Data\n",
    "Conduct exploratory data analysis to understand the underlying patterns and relationships in the data. Visualizations can be helpful in identifying trends and outliers. Make sure that the EDA you present explains the feature engineering choices you made. Moreover, when we read through your notebook, we expect to understand why you choose the particular baseline model and why you engineer your features the way you did. This section would be a great way to provide your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92327dfc-c9b3-4f8f-8f11-2e99082ef0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1338 entries, 0 to 1338\n",
      "Data columns (total 43 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Species                1338 non-null   object \n",
      " 1   Owner                  1331 non-null   object \n",
      " 2   Country.of.Origin      1337 non-null   object \n",
      " 3   Farm.Name              980 non-null    object \n",
      " 4   Lot.Number             276 non-null    object \n",
      " 5   Mill                   1021 non-null   object \n",
      " 6   ICO.Number             1179 non-null   object \n",
      " 7   Company                1130 non-null   object \n",
      " 8   Altitude               1112 non-null   object \n",
      " 9   Region                 1279 non-null   object \n",
      " 10  Producer               1107 non-null   object \n",
      " 11  Number.of.Bags         1338 non-null   int64  \n",
      " 12  Bag.Weight             1338 non-null   object \n",
      " 13  In.Country.Partner     1338 non-null   object \n",
      " 14  Harvest.Year           1291 non-null   object \n",
      " 15  Grading.Date           1338 non-null   object \n",
      " 16  Owner.1                1331 non-null   object \n",
      " 17  Variety                1113 non-null   object \n",
      " 18  Processing.Method      1169 non-null   object \n",
      " 19  Aroma                  1338 non-null   float64\n",
      " 20  Flavor                 1338 non-null   float64\n",
      " 21  Aftertaste             1338 non-null   float64\n",
      " 22  Acidity                1338 non-null   float64\n",
      " 23  Body                   1338 non-null   float64\n",
      " 24  Balance                1338 non-null   float64\n",
      " 25  Uniformity             1338 non-null   float64\n",
      " 26  Clean.Cup              1338 non-null   float64\n",
      " 27  Sweetness              1338 non-null   float64\n",
      " 28  Cupper.Points          1338 non-null   float64\n",
      " 29  Total.Cup.Points       1338 non-null   float64\n",
      " 30  Moisture               1338 non-null   float64\n",
      " 31  Category.One.Defects   1338 non-null   int64  \n",
      " 32  Quakers                1337 non-null   float64\n",
      " 33  Color                  1069 non-null   object \n",
      " 34  Category.Two.Defects   1338 non-null   int64  \n",
      " 35  Expiration             1338 non-null   object \n",
      " 36  Certification.Body     1338 non-null   object \n",
      " 37  Certification.Address  1338 non-null   object \n",
      " 38  Certification.Contact  1338 non-null   object \n",
      " 39  unit_of_measurement    1338 non-null   object \n",
      " 40  altitude_low_meters    1109 non-null   float64\n",
      " 41  altitude_high_meters   1109 non-null   float64\n",
      " 42  altitude_mean_meters   1109 non-null   float64\n",
      "dtypes: float64(16), int64(3), object(24)\n",
      "memory usage: 459.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a7ebf-6d22-41cb-8b46-df92056d7440",
   "metadata": {},
   "source": [
    "### Data cleaning and preprocessing\n",
    "- Clean text data\n",
    "- Feature selection\n",
    "- Imputation\n",
    "- Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b15d0af-5475-4933-9bc0-df5d40560104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Country.of.Origin</th>\n",
       "      <th>Farm.Name</th>\n",
       "      <th>Lot.Number</th>\n",
       "      <th>Mill</th>\n",
       "      <th>ICO.Number</th>\n",
       "      <th>Company</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Region</th>\n",
       "      <th>...</th>\n",
       "      <th>Color</th>\n",
       "      <th>Category.Two.Defects</th>\n",
       "      <th>Expiration</th>\n",
       "      <th>Certification.Body</th>\n",
       "      <th>Certification.Address</th>\n",
       "      <th>Certification.Contact</th>\n",
       "      <th>unit_of_measurement</th>\n",
       "      <th>altitude_low_meters</th>\n",
       "      <th>altitude_high_meters</th>\n",
       "      <th>altitude_mean_meters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arabica</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>2014/2015</td>\n",
       "      <td>metad agricultural developmet plc</td>\n",
       "      <td>1950-2200</td>\n",
       "      <td>guji-hambela</td>\n",
       "      <td>...</td>\n",
       "      <td>Green</td>\n",
       "      <td>0</td>\n",
       "      <td>April 3rd, 2016</td>\n",
       "      <td>METAD Agricultural Development plc</td>\n",
       "      <td>309fcf77415a3661ae83e027f7e5f05dad786e44</td>\n",
       "      <td>19fef5a731de2db57d16da10287413f5f99bc2dd</td>\n",
       "      <td>m</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabica</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>2014/2015</td>\n",
       "      <td>metad agricultural developmet plc</td>\n",
       "      <td>1950-2200</td>\n",
       "      <td>guji-hambela</td>\n",
       "      <td>...</td>\n",
       "      <td>Green</td>\n",
       "      <td>1</td>\n",
       "      <td>April 3rd, 2016</td>\n",
       "      <td>METAD Agricultural Development plc</td>\n",
       "      <td>309fcf77415a3661ae83e027f7e5f05dad786e44</td>\n",
       "      <td>19fef5a731de2db57d16da10287413f5f99bc2dd</td>\n",
       "      <td>m</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2075.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Species      Owner Country.of.Origin  Farm.Name Lot.Number       Mill  \\\n",
       "0  Arabica  metad plc          Ethiopia  metad plc        NaN  metad plc   \n",
       "1  Arabica  metad plc          Ethiopia  metad plc        NaN  metad plc   \n",
       "\n",
       "  ICO.Number                            Company   Altitude        Region  ...  \\\n",
       "0  2014/2015  metad agricultural developmet plc  1950-2200  guji-hambela  ...   \n",
       "1  2014/2015  metad agricultural developmet plc  1950-2200  guji-hambela  ...   \n",
       "\n",
       "   Color  Category.Two.Defects       Expiration  \\\n",
       "0  Green                     0  April 3rd, 2016   \n",
       "1  Green                     1  April 3rd, 2016   \n",
       "\n",
       "                   Certification.Body  \\\n",
       "0  METAD Agricultural Development plc   \n",
       "1  METAD Agricultural Development plc   \n",
       "\n",
       "                      Certification.Address  \\\n",
       "0  309fcf77415a3661ae83e027f7e5f05dad786e44   \n",
       "1  309fcf77415a3661ae83e027f7e5f05dad786e44   \n",
       "\n",
       "                      Certification.Contact unit_of_measurement  \\\n",
       "0  19fef5a731de2db57d16da10287413f5f99bc2dd                   m   \n",
       "1  19fef5a731de2db57d16da10287413f5f99bc2dd                   m   \n",
       "\n",
       "  altitude_low_meters altitude_high_meters  altitude_mean_meters  \n",
       "0              1950.0               2200.0                2075.0  \n",
       "1              1950.0               2200.0                2075.0  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f00e88d-59cd-4d5f-863e-58dd4e0d1e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMERIC:\n",
      "Index(['Number.of.Bags', 'Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body',\n",
      "       'Balance', 'Uniformity', 'Clean.Cup', 'Sweetness', 'Cupper.Points',\n",
      "       'Total.Cup.Points', 'Moisture', 'Category.One.Defects', 'Quakers',\n",
      "       'Category.Two.Defects', 'altitude_low_meters', 'altitude_high_meters',\n",
      "       'altitude_mean_meters'],\n",
      "      dtype='object')\n",
      "\n",
      "CATEGORICAL:\n",
      "Index(['Species', 'Owner', 'Country.of.Origin', 'Farm.Name', 'Lot.Number',\n",
      "       'Mill', 'ICO.Number', 'Company', 'Altitude', 'Region', 'Producer',\n",
      "       'Bag.Weight', 'In.Country.Partner', 'Harvest.Year', 'Grading.Date',\n",
      "       'Owner.1', 'Variety', 'Processing.Method', 'Color', 'Expiration',\n",
      "       'Certification.Body', 'Certification.Address', 'Certification.Contact',\n",
      "       'unit_of_measurement'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# split into numeric and categorical features\n",
    "numeric = df.select_dtypes(include=[np.number])\n",
    "categorical = df.select_dtypes(exclude=[np.number])\n",
    "print('NUMERIC:')\n",
    "print(numeric.columns)\n",
    "print('\\nCATEGORICAL:')\n",
    "print(categorical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d3846c-f444-416e-9a3c-f62df9953ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Bag.Weight values before processing:\n",
      "['60 kg' '1' '30 kg' '69 kg' '1 kg' '2 kg,lbs' '6' '3 lbs' '50 kg' '2 lbs'\n",
      " '100 lbs' '15 kg' '2 kg' '2' '70 kg' '19200 kg' '5 lbs' '1 kg,lbs' '6 kg'\n",
      " '0 lbs' '46 kg' '40 kg' '20 kg' '34 kg' '1 lbs' '660 kg' '18975 kg'\n",
      " '12000 kg' '35 kg' '66 kg' '80 kg' '132 lbs' '5 kg' '25 kg' '59 kg'\n",
      " '18000 kg' '150 lbs' '9000 kg' '18 kg' '10 kg' '29 kg' '1218 kg' '4 lbs'\n",
      " '0 kg' '13800 kg' '1500 kg' '24 kg' '80 lbs' '8 kg' '3 kg' '350 kg'\n",
      " '67 kg' '4 kg' '55 lbs' '100 kg' '130 lbs']\n",
      "\n",
      "Unique Bag.Weight values after processing:\n",
      "[   60     1    30    69     2     6    50    45    15    70 19200     0\n",
      "    46    40    20    34   660 18975 12000    35    66    80     5    25\n",
      "    59 18000    68  9000    18    10    29  1218 13800  1500    24    36\n",
      "     8     3   350    67     4   100]\n"
     ]
    }
   ],
   "source": [
    "# PROCESS BAG WEIGHT DATA\n",
    "print('Unique Bag.Weight values before processing:')\n",
    "print(categorical['Bag.Weight'].unique())\n",
    "def fix_bagweight(text):\n",
    "    vals = text.split()\n",
    "    bag_weight = int(vals[0])\n",
    "    # convert to kilograms\n",
    "    if len(vals) > 1:\n",
    "        if vals[1] == 'lbs':\n",
    "            bag_weight *= 0.453592\n",
    "    return round(bag_weight)\n",
    "\n",
    "# add bag weight to numeric, drop from categorical\n",
    "df['Bag.Weight'] = df['Bag.Weight'].apply(fix_bagweight)\n",
    "categorical = categorical.drop(columns='Bag.Weight')\n",
    "\n",
    "print('\\nUnique Bag.Weight values after processing:')\n",
    "print(df['Bag.Weight'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23882ee-52c6-495d-a74e-350742f34ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Bag.Weight values before processing:\n",
      "['2014' nan '2013' '2012' 'March 2010' 'Sept 2009 - April 2010'\n",
      " 'May-August' '2009/2010' '2015' '2011' '2016' '2015/2016' '2010'\n",
      " 'Fall 2009' '2017' '2009 / 2010' '2010-2011' '2009-2010' '2009 - 2010'\n",
      " '2013/2014' '2017 / 2018' 'mmm' 'December 2009-March 2010' '2014/2015'\n",
      " '2011/2012' 'January 2011' '4T/10' '2016 / 2017' '23 July 2010'\n",
      " 'January Through April' '1T/2011' '4t/2010' '4T/2010'\n",
      " 'August to December' 'Mayo a Julio' '47/2010' 'Abril - Julio' '4t/2011'\n",
      " 'Abril - Julio /2011' 'Spring 2011 in Colombia.' '3T/2011' '2016/2017'\n",
      " '1t/2011' '2018' '4T72010' '08/09 crop']\n",
      "\n",
      "Unique Harvest.Year values after processing:\n",
      "[ 9. nan 10. 11. 13. 14.  8. 12.  7.  6.  5.]\n"
     ]
    }
   ],
   "source": [
    "# PROCESS HARVEST YEAR DATA\n",
    "print('Unique Bag.Weight values before processing:')\n",
    "print(categorical['Harvest.Year'].unique())\n",
    "def fix_harvestyear(text):\n",
    "    text = str(text)\n",
    "    yr_pattern = re.compile('\\d{4}(?=\\D|$)')\n",
    "    match = yr_pattern.search(text)\n",
    "    if match:\n",
    "        year = match.group()\n",
    "        return 2023 - float(year)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# add bag weight to numeric, drop from categorical\n",
    "df['Harvest.Year'] = df['Harvest.Year'].apply(fix_harvestyear)\n",
    "categorical = categorical.drop(columns='Harvest.Year')\n",
    "\n",
    "print('\\nUnique Harvest.Year values after processing:')\n",
    "print(df['Harvest.Year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93dc818f-f4ec-424d-89a0-0be2bc82c97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1338\n"
     ]
    }
   ],
   "source": [
    "# drop outliers\n",
    "g = df.columns.to_series().groupby(df.dtypes).groups\n",
    "g={k.name: list(v) for k, v in g.items()}\n",
    "numerical_vars = df[g['int64']+g['float64']].columns\n",
    "df_idx = df[numerical_vars]\n",
    "drop_idx = df_idx[(np.abs(stats.zscore(df_idx)) > 3).any(axis=1)].index\n",
    "print(len(df))\n",
    "df = df.drop(drop_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7650da40-4334-4b23-9952-1017d4c8c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine countries with less observations as \"Others\"\n",
    "df['Country.of.Origin'] = df['Country.of.Origin'].apply(lambda x: 'Others' if x not in ['Mexico', 'Colombia', 'Guatemala', 'Brazil', 'Taiwan',\n",
    "       'United States (Hawaii)'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eea6ddf8-76e0-4c6d-b06b-cb8576df410c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3        9.0\n",
       "4        9.0\n",
       "5       10.0\n",
       "6       11.0\n",
       "8       13.0\n",
       "        ... \n",
       "1266     9.0\n",
       "1271     9.0\n",
       "1272    11.0\n",
       "1275    11.0\n",
       "1281    11.0\n",
       "Name: Harvest.Year, Length: 1184, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Harvest.Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce9a824c-6dab-487f-b26d-b53c4b215fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1., nan,  3.,  0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate expiration year\n",
    "df['Expiration_year'] = df['Expiration'].str.extract('(\\d{4})')\n",
    "df['Expiration_year']=df['Expiration_year'].apply(lambda x :  float(x) if x!=None else np.nan)\n",
    "df['Expiration_year']=df['Expiration_year']+df['Harvest.Year']-2023\n",
    "df['Expiration_year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d7e797b-45f8-4ce5-9b77-6137af15c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\n",
    "    'Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body',\n",
    "   'Balance', 'Uniformity', 'Clean.Cup', 'Sweetness', 'Moisture',\n",
    "   'Category.One.Defects', 'Quakers', 'Category.Two.Defects',\n",
    "    'Harvest.Year', 'Bag.Weight', 'Expiration_year', 'Color', 'Country.of.Origin'\n",
    "]\n",
    "\n",
    "categorical_cols = ['Color', 'Country.of.Origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c10f31c-fef6-46cc-a9a0-bfb7168d4d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (947, 25)\n",
      "y_train shape: (947,)\n",
      "X_test shape: (237, 25)\n",
      "y_test shape: (237,)\n"
     ]
    }
   ],
   "source": [
    "# train linear regression on numeric data\n",
    "\n",
    "train = df[predictors]\n",
    "y = df['Cupper.Points']\n",
    "\n",
    "\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=0, \n",
    "                                                    shuffle=True)\n",
    "\n",
    "# ohe categorical predicotrs\n",
    "ohe = OneHotEncoder(drop='first', \n",
    "                    sparse=False, \n",
    "                    handle_unknown='ignore') \n",
    "ohe_train = ohe.fit_transform(X_train[categorical_cols])\n",
    "# combine numerical and categorical\n",
    "X_train = pd.merge(\n",
    "    X_train.drop(columns=categorical_cols).reset_index(drop=True),\n",
    "    pd.DataFrame(ohe_train, columns=ohe.get_feature_names_out()).reset_index(drop=True),\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "ohe_test = ohe.transform(X_test[categorical_cols])\n",
    "# combine numerical and categorical\n",
    "X_test = pd.merge(\n",
    "    X_test.drop(columns=categorical_cols).reset_index(drop=True),\n",
    "    pd.DataFrame(ohe_test, columns=ohe.get_feature_names_out()).reset_index(drop=True),\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "# impute missing data\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('y_train shape:',y_train.shape)\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('y_test shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c74a36-b9eb-4ba0-a4fb-07c2563a87fb",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "Select an appropriate machine learning model or statistical technique to solve the problem at hand. Train and evaluate the model using appropriate metrics and techniques. This would act as your baseline model, against which you will compare to improve your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0538a2f1-5a6f-4696-b7fa-9fbebf3b8dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression train score: 0.7542781608142579\n",
      "Linear regression test score: 0.765411202932506\n"
     ]
    }
   ],
   "source": [
    "# simple Linear Regression Model\n",
    "lr= LinearRegression().fit(X_train, y_train)\n",
    "print('Linear regression train score:',lr.score(X_train, y_train))\n",
    "print('Linear regression test score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "369a8f43-e172-424a-844b-a945f3a53430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled LR Coefficients\n",
      "Flavor                    0.3134\n",
      "Aftertaste                0.2726\n",
      "Balance                   0.2273\n",
      "Acidity                   0.1413\n",
      "Country.of.Origin_Taiwan  -0.14\n",
      "Moisture                  -0.122\n",
      "Body                      0.122\n",
      "Country.of.Origin_Guatemala -0.0802\n",
      "Aroma                     0.0509\n",
      "Country.of.Origin_Colombia -0.049\n",
      "Country.of.Origin_United States (Hawaii) -0.0409\n",
      "Clean.Cup                 -0.0365\n",
      "Sweetness                 0.0362\n",
      "Color_Green               -0.0199\n",
      "Color_Bluish-Green        -0.0184\n",
      "Country.of.Origin_Mexico  -0.0151\n",
      "Uniformity                0.0096\n",
      "Harvest.Year              -0.0083\n",
      "Category.One.Defects      -0.0062\n",
      "Color_nan                 0.006\n",
      "Country.of.Origin_Others  -0.0056\n",
      "Expiration_year           0.0053\n",
      "Category.Two.Defects      -0.0023\n",
      "Quakers                   0.0019\n",
      "Bag.Weight                -0.0001\n"
     ]
    }
   ],
   "source": [
    "#unscaled\n",
    "print('Unscaled LR Coefficients')\n",
    "name_coef = zip(imputer.get_feature_names_out(),lr.coef_)\n",
    "for name, coef in sorted(name_coef, key=lambda x:np.abs(x[1]), reverse=True):\n",
    "    print(f\"{name:<25} {round(coef,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "138f180c-5060-492d-b111-f1bfe8bbcd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression train score: 0.7542781608142579\n",
      "Linear regression test score: 0.765411202932507\n"
     ]
    }
   ],
   "source": [
    "# simple Linear Regression Model\n",
    "lr= LinearRegression().fit(X_train_scaled, y_train)\n",
    "print('Linear regression train score:',lr.score(X_train_scaled, y_train))\n",
    "print('Linear regression test score:', lr.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfb2d4ae-fcf9-4f84-9932-c5407610aee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled LR Coefficients\n",
      "Flavor                    0.0954\n",
      "Aftertaste                0.0845\n",
      "Balance                   0.072\n",
      "Acidity                   0.0412\n",
      "Body                      0.0327\n",
      "Country.of.Origin_Taiwan  -0.0319\n",
      "Country.of.Origin_Guatemala -0.0284\n",
      "Country.of.Origin_Colombia -0.0179\n",
      "Harvest.Year              -0.0148\n",
      "Aroma                     0.0147\n",
      "Color_Green               -0.0095\n",
      "Country.of.Origin_United States (Hawaii) -0.0089\n",
      "Category.Two.Defects      -0.0081\n",
      "Clean.Cup                 -0.0067\n",
      "Sweetness                 0.0065\n",
      "Moisture                  -0.0059\n",
      "Country.of.Origin_Mexico  -0.0056\n",
      "Color_Bluish-Green        -0.0052\n",
      "Category.One.Defects      -0.0049\n",
      "Bag.Weight                -0.0036\n",
      "Country.of.Origin_Others  -0.0026\n",
      "Uniformity                0.0025\n",
      "Color_nan                 0.0024\n",
      "Expiration_year           0.0024\n",
      "Quakers                   0.0016\n"
     ]
    }
   ],
   "source": [
    "print('Scaled LR Coefficients')\n",
    "name_coef = zip(imputer.get_feature_names_out(),lr.coef_)\n",
    "for name, coef in sorted(name_coef, key=lambda x:np.abs(x[1]), reverse=True):\n",
    "    print(f\"{name:<25} {round(coef,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0c0ee-a22d-4acf-af40-aae4729728a7",
   "metadata": {},
   "source": [
    "## Interpret the result\n",
    "Analyze the results of the model and communicate the findings. This may involve creating visualizations or presenting the results in a clear and concise manner. The findings here must lead to your choice of the final model.\n",
    "\n",
    "**-> calculate confidence interval (bootstrap?)\n",
    "--> plot importance of coefficients\n",
    "-> blabla...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f775a-a9f5-45c4-beec-2f269d5b2bb7",
   "metadata": {},
   "source": [
    "## Final Model Pipeline: \n",
    "By this step, you should clearly understand and reason for choosing a particular machine learning technique. You are only expected to choose a technique and set up the pipeline to ensure that you are able to train it and run the required experiments. You are not required to tune your model to get optimal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fefb46-0e25-452f-af7c-a15ebd77b062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
